{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Heart Disease Prediction Using Various Machine Learning Techniques\n","We would be working with the heart disease prediction data that is found in UCI repository. Below is an actual link of the data that we would be working. We would be exploring various machine learning techniques that could be used for predictions and gain a good understanding of them by taking into consideration some of the important metrics such as accuracy, precision and recall. There are other metrics that are also present and are important that we would be exploring and which could be seen at the end of the project. \n","\n","We see that there are some features that we would be considering for the machine learning model. Some of the actual features that we would be considering are as follows:-\n","1. age \n","2. sex \n","3. chest pain type (4 values) \n","4. resting blood pressure \n","5. serum cholestoral in mg/dl \n","6. fasting blood sugar > 120 mg/dl\n","7. resting electrocardiographic results (values 0,1,2)\n","8. maximum heart rate achieved \n","9. exercise induced angina \n","10. oldpeak = ST depression induced by exercise relative to rest \n","11. the slope of the peak exercise ST segment \n","12. number of major vessels (0-3) colored by flourosopy \n","13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n","\n","We would be limiting ourselves to work with small dataset so that we gain an understanding of the overall workflow of machine learning. Once we gain a good understanding of the workflow of machine learning, we can explore other datasets and follow the same procedure for datasets that are large as the process stays the same. \n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns                                                          \n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, log_loss \n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler                                \n","from sklearn.svm import SVC                                                     \n","from sklearn.preprocessing import Normalizer                                    \n","from sklearn.linear_model import LogisticRegression                             \n","from sklearn.naive_bayes import GaussianNB                                      \n","from sklearn.ensemble import RandomForestClassifier                              "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df = pd.read_csv('heart.csv')               "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>125</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>203</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>3.1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>145</td>\n","      <td>174</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>125</td>\n","      <td>1</td>\n","      <td>2.6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>61</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>148</td>\n","      <td>203</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>138</td>\n","      <td>294</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>106</td>\n","      <td>0</td>\n","      <td>1.9</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   52    1   0       125   212    0        1      168      0      1.0      2   \n","1   53    1   0       140   203    1        0      155      1      3.1      0   \n","2   70    1   0       145   174    0        1      125      1      2.6      0   \n","3   61    1   0       148   203    0        1      161      0      0.0      2   \n","4   62    0   0       138   294    1        1      106      0      1.9      1   \n","\n","   ca  thal  target  \n","0   2     3       0  \n","1   0     3       0  \n","2   0     3       0  \n","3   1     3       0  \n","4   3     2       0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()                        "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1025 entries, 0 to 1024\n","Data columns (total 14 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   age       1025 non-null   int64  \n"," 1   sex       1025 non-null   int64  \n"," 2   cp        1025 non-null   int64  \n"," 3   trestbps  1025 non-null   int64  \n"," 4   chol      1025 non-null   int64  \n"," 5   fbs       1025 non-null   int64  \n"," 6   restecg   1025 non-null   int64  \n"," 7   thalach   1025 non-null   int64  \n"," 8   exang     1025 non-null   int64  \n"," 9   oldpeak   1025 non-null   float64\n"," 10  slope     1025 non-null   int64  \n"," 11  ca        1025 non-null   int64  \n"," 12  thal      1025 non-null   int64  \n"," 13  target    1025 non-null   int64  \n","dtypes: float64(1), int64(13)\n","memory usage: 112.2 KB\n"]}],"source":["df.info()      #Getting the info of the dataframe "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.00000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>54.434146</td>\n","      <td>0.695610</td>\n","      <td>0.942439</td>\n","      <td>131.611707</td>\n","      <td>246.00000</td>\n","      <td>0.149268</td>\n","      <td>0.529756</td>\n","      <td>149.114146</td>\n","      <td>0.336585</td>\n","      <td>1.071512</td>\n","      <td>1.385366</td>\n","      <td>0.754146</td>\n","      <td>2.323902</td>\n","      <td>0.513171</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9.072290</td>\n","      <td>0.460373</td>\n","      <td>1.029641</td>\n","      <td>17.516718</td>\n","      <td>51.59251</td>\n","      <td>0.356527</td>\n","      <td>0.527878</td>\n","      <td>23.005724</td>\n","      <td>0.472772</td>\n","      <td>1.175053</td>\n","      <td>0.617755</td>\n","      <td>1.030798</td>\n","      <td>0.620660</td>\n","      <td>0.500070</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>94.000000</td>\n","      <td>126.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>71.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>48.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>120.000000</td>\n","      <td>211.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>132.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>56.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>130.000000</td>\n","      <td>240.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>152.000000</td>\n","      <td>0.000000</td>\n","      <td>0.800000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>61.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>140.000000</td>\n","      <td>275.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>166.000000</td>\n","      <td>1.000000</td>\n","      <td>1.800000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>77.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>200.000000</td>\n","      <td>564.00000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>202.000000</td>\n","      <td>1.000000</td>\n","      <td>6.200000</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               age          sex           cp     trestbps        chol  \\\n","count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n","mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n","std       9.072290     0.460373     1.029641    17.516718    51.59251   \n","min      29.000000     0.000000     0.000000    94.000000   126.00000   \n","25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n","50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n","75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n","max      77.000000     1.000000     3.000000   200.000000   564.00000   \n","\n","               fbs      restecg      thalach        exang      oldpeak  \\\n","count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n","mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n","std       0.356527     0.527878    23.005724     0.472772     1.175053   \n","min       0.000000     0.000000    71.000000     0.000000     0.000000   \n","25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n","50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n","75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n","max       1.000000     2.000000   202.000000     1.000000     6.200000   \n","\n","             slope           ca         thal       target  \n","count  1025.000000  1025.000000  1025.000000  1025.000000  \n","mean      1.385366     0.754146     2.323902     0.513171  \n","std       0.617755     1.030798     0.620660     0.500070  \n","min       0.000000     0.000000     0.000000     0.000000  \n","25%       1.000000     0.000000     2.000000     0.000000  \n","50%       1.000000     0.000000     2.000000     1.000000  \n","75%       2.000000     1.000000     3.000000     1.000000  \n","max       2.000000     4.000000     3.000000     1.000000  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()        #Used for understanding the spread in the data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>125</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>203</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>3.1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>145</td>\n","      <td>174</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>125</td>\n","      <td>1</td>\n","      <td>2.6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>61</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>148</td>\n","      <td>203</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>138</td>\n","      <td>294</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>106</td>\n","      <td>0</td>\n","      <td>1.9</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   52    1   0       125   212    0        1      168      0      1.0      2   \n","1   53    1   0       140   203    1        0      155      1      3.1      0   \n","2   70    1   0       145   174    0        1      125      1      2.6      0   \n","3   61    1   0       148   203    0        1      161      0      0.0      2   \n","4   62    0   0       138   294    1        1      106      0      1.9      1   \n","\n","   ca  thal  target  \n","0   2     3       0  \n","1   0     3       0  \n","2   0     3       0  \n","3   1     3       0  \n","4   3     2       0  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["X = df.drop(['target'], axis = 1)\n","y = df['target']"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.32, random_state = 40)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(697, 13)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape      "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(328, 13)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X_test.shape "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","ms = MinMaxScaler()\n","\n","x_train = ms.fit_transform(X_train)\n","x_test = ms.transform(X_test)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["sc=StandardScaler()\n","sc.fit(X_train)\n","x_train=sc.transform(X_train)\n","x_test=sc.transform(X_test)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression  with accuracy : 0.8262195121951219\n","Naive Bayes  with accuracy : 0.823170731707317\n","Support Vector Machine  with accuracy : 0.9420731707317073\n","K-Nearest Neighbors  with accuracy : 0.8536585365853658\n","Decision Tree  with accuracy : 0.9817073170731707\n","Random Forest  with accuracy : 0.9908536585365854\n","Bagging  with accuracy : 0.975609756097561\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\sulth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["AdaBoost  with accuracy : 0.9115853658536586\n","Gradient Boosting  with accuracy : 0.975609756097561\n","Extra Trees  with accuracy : 0.9817073170731707\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# create instances of all models\n","models = {\n","    'Logistic Regression': LogisticRegression(),\n","    'Naive Bayes': GaussianNB(),\n","    'Support Vector Machine': SVC(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'Bagging': BaggingClassifier(),\n","    'AdaBoost': AdaBoostClassifier(),\n","    'Gradient Boosting': GradientBoostingClassifier(),\n","    'Extra Trees': ExtraTreeClassifier(),\n","}\n","\n","\n","for name, md in models.items():\n","    md.fit(x_train,y_train)\n","    ypred = md.predict(x_test)\n","    \n","    print(f\"{name}  with accuracy : {accuracy_score(y_test,ypred)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest Classifier\n","We would be using one more machine learning algorithm called random forest classifier. This machine learning model has a few hyperparameters that must be tuned in order to get the most accurate result. I just found out that the best values that we would be using right would be the max_depth which is assigned the value 10 and random state which we would be giving the value to be 100. We would do the same thing where we first fit the model and then, we use the predict which will help us get the predictions. \n","<br> \n","It is good to go through the theory behind machine learning models. Here is a website that is one of the most useful ones that I found in the internet that talks about random forests in depth. <br> "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["0.9908536585365854"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["rfc = RandomForestClassifier()\n","rfc.fit(x_train, y_train)\n","y_test_predict_scaled = rfc.predict(x_test)\n","accuracy_score(y_test,y_test_predict_scaled)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def recommendation(age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal):\n","    data = np.array([[age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal]])\n","    transformed_features = ms.fit_transform(data)\n","    transformed_features = sc.fit_transform(transformed_features)\n","    prediction = rfc.predict(transformed_features).reshape(1,-1)\n","    \n","    return prediction[0] \n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import pickle\n","pickle.dump(rfc,open('model.pkl','wb'))\n","pickle.dump(ms,open('minmaxscaler.pkl','wb'))\n","pickle.dump(sc,open('standscaler.pkl','wb'))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["with open('model.pkl', 'wb') as model_file:\n","    pickle.dump(rfc, model_file)\n","\n","with open('minmaxscaler.pkl', 'wb') as minmaxscaler_file:\n","    pickle.dump(ms, minmaxscaler_file)\n","\n","with open('standscaler.pkl', 'wb') as standscaler_file:\n","    pickle.dump(sc, standscaler_file)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
